{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Application\n",
    "# Sentiment analysis\n",
    "# customer Support \n",
    "# Language detection\n",
    "# fakenews detection\n",
    "\n",
    "            # Pipleine\n",
    "# text acquire\n",
    "# preprocessing\n",
    "# Vectolization\n",
    "# Modeling ( common --> naive bayes , random forest)\n",
    "# Evalutations\n",
    "# Deploy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv('Emotion_Dataset/text_emotion.csv')\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   10000 non-null  int64 \n",
      " 1   sentiment  10000 non-null  object\n",
      " 2   author     10000 non-null  object\n",
      " 3   content    10000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 312.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "worry         3115\n",
       "sadness       2216\n",
       "neutral       1857\n",
       "surprise       562\n",
       "hate           535\n",
       "happiness      469\n",
       "love           369\n",
       "relief         227\n",
       "fun            211\n",
       "empty          194\n",
       "enthusiasm     132\n",
       "boredom         69\n",
       "anger           44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_temp.iloc[:10000].copy()\n",
    "df.head()\n",
    "df.info()\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tiffanylue i know  i was listenin to bad habit...\n",
       "1    Layin n bed with a headache  ughhhhwaitin on y...\n",
       "2                        Funeral ceremonygloomy friday\n",
       "3                  wants to hang out with friends SOON\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# remove puncation\n",
    "\n",
    "import string\n",
    "exclude = string.punctuation\n",
    "\n",
    "def remove_pun(text):\n",
    "    return text.translate(str.maketrans('' , '' , exclude))\n",
    "\n",
    "df['content']  = df['content'].apply(remove_pun)\n",
    "df['content'].iloc[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tiffanylue  know   listenin  bad habit earlier...\n",
       "1           Layin n bed   headache ughhhhwaitin   call\n",
       "2                        Funeral ceremonygloomy friday\n",
       "3                           wants  hang   friends SOON\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    dummy = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            dummy.append(\"\")\n",
    "        else:\n",
    "            dummy.append(word)\n",
    "    x = dummy[:]\n",
    "    dummy.clear()\n",
    "    return \" \" .join(x)\n",
    "\n",
    "df['content']  = df['content'].apply(remove_stopwords)\n",
    "df['content'].iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tiffanylue  know   listenin  bad habit earlier...\n",
       "1           layin n bed   headache ughhhhwaitin   call\n",
       "2                        funeral ceremonygloomy friday\n",
       "3                           wants  hang   friends soon\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to lower case\n",
    "\n",
    "df['content']  = df['content'].str.lower()\n",
    "df['content'].iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "X = df['content']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size= 0.2 , random_state=1)\n",
    "\n",
    "y_train[0:5]\n",
    "X_train[:5]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 5000), (2000, 5000))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorization(bag or words)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features= 5000)\n",
    "\n",
    "\n",
    "X_train_bow = bow.fit_transform(X_train).toarray()\n",
    "x_test_bow = bow.transform(X_test).toarray()\n",
    "\n",
    "X_train_bow.shape , x_test_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive bayes fucntion\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "\n",
    "gb = GaussianNB()\n",
    "\n",
    "gb.fit(X_train_bow , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   1,   0,   0,   2,   1,   2,   0,   0,   0,   1],\n",
       "       [  2,   1,   1,   0,   3,   0,   1,   0,   1,   0,   1,   0,   3],\n",
       "       [  2,   0,   1,   1,   3,   5,   4,   5,   6,   1,   4,   0,   7],\n",
       "       [  0,   0,   0,   2,   0,   2,   0,   1,   6,   0,   7,   2,   3],\n",
       "       [  0,   0,   0,   3,   2,   2,   4,   4,  14,   1,   7,   4,   5],\n",
       "       [  1,   1,   3,   2,   6,  14,   7,   7,  16,   7,  14,   3,   9],\n",
       "       [  0,   3,   3,   2,   1,  11,  10,   3,  29,   1,  17,   2,  18],\n",
       "       [  1,   2,   0,   6,   9,   8,   2,   5,  12,   4,  13,   5,  10],\n",
       "       [ 26,  18,  23,  35,  27,  23,  19,  21,  71,  20,  54,  22,  32],\n",
       "       [  3,   1,   0,   3,   2,   3,   2,   3,  11,   2,   9,   3,   8],\n",
       "       [  6,  12,  15,  22,  25,  28,  30,  31,  69,  20,  86,  22,  58],\n",
       "       [  4,   1,   4,   6,   5,   8,  11,   2,  17,   4,  13,   5,  11],\n",
       "       [ 15,  17,  20,  29,  40,  44,  47,  38, 128,  18, 117,  41,  95]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gb.predict(x_test_bow)\n",
    "\n",
    "print(accuracy_score(y_test , y_pred))\n",
    "\n",
    "confusion_matrix(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rcf = RandomForestClassifier()\n",
    "rcf.fit(X_train_bow , y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   1,   1,   1,   0,   1,   0,   3],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,   0,   2,   0,   2,   1,   7],\n",
       "       [  0,   0,   3,   0,   0,   0,   1,   0,   7,   0,   9,   2,  17],\n",
       "       [  1,   0,   0,   0,   0,   1,   0,   1,   7,   0,   2,   0,  11],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  15,   1,  10,   0,  20],\n",
       "       [  0,   0,   1,   0,   0,   5,   0,   2,  17,   4,  18,   3,  40],\n",
       "       [  0,   0,   1,   0,   0,   2,  10,   0,  24,   0,  27,   2,  34],\n",
       "       [  1,   0,   0,   0,   0,   1,   1,   4,  17,   1,  13,   2,  37],\n",
       "       [  0,   0,   7,   0,   0,   5,   5,   2, 168,   5,  67,  10, 122],\n",
       "       [  0,   0,   0,   1,   0,   1,   0,   0,  10,   1,  12,   1,  24],\n",
       "       [  1,   0,   4,   0,   1,   3,   5,   5,  91,   2, 113,  13, 186],\n",
       "       [  2,   0,   2,   0,   0,   2,   2,   1,  34,   0,   8,   8,  32],\n",
       "       [  3,   0,   2,   4,   1,   9,  10,   4, 167,   6, 141,   9, 293]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rcf.predict(x_test_bow)\n",
    "\n",
    "print(accuracy_score(y_test , y_pred))\n",
    "\n",
    "confusion_matrix(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf - idf for vectorlization\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf = TfidfVectorizer(max_features= 5000)\n",
    "\n",
    "X_train_tf= tf_idf.fit_transform(X_train).toarray()\n",
    "x_test_tf = tf_idf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   1,   0,   1,   0,   2,   0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,   4,   0,   2,   0,   6],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,  10,   0,   8,   1,  19],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   4,   0,   2,   0,  16],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  10,   0,   8,   0,  28],\n",
       "       [  0,   0,   1,   0,   0,   1,   0,   4,  13,   0,  22,   1,  48],\n",
       "       [  0,   0,   0,   0,   0,   0,  11,   0,  26,   0,  24,   0,  39],\n",
       "       [  0,   0,   0,   0,   1,   0,   2,  11,  14,   0,  11,   1,  37],\n",
       "       [  0,   0,   3,   0,   0,   1,   7,   5, 134,   3,  56,  10, 172],\n",
       "       [  0,   0,   0,   1,   0,   1,   1,   2,  11,   1,  12,   0,  21],\n",
       "       [  0,   2,   0,   0,   0,   3,   9,   7,  61,   0, 123,   6, 213],\n",
       "       [  1,   0,   0,   0,   0,   1,   3,   1,  23,   0,  10,   6,  46],\n",
       "       [  0,   0,   0,   2,   0,   3,   9,   2, 142,   1, 122,   4, 364]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf = RandomForestClassifier()\n",
    "rcf.fit(X_train_tf , y_train)\n",
    "y_pred = rcf.predict(x_test_tf)\n",
    "\n",
    "print(accuracy_score(y_test , y_pred))\n",
    "\n",
    "confusion_matrix(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemale techniques\n",
    "# heuristic featues\n",
    "# ml --> deep learning\n",
    "# imbalace datset (xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
